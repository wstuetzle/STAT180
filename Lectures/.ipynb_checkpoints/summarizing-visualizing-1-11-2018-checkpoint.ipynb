{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Summarizing and visualizing features </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import code libraries or \"modules\" in Python lingo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import sys\n",
    "from datascience import *\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If you want to run this notebook on Azure, its easiest to upload the notebook, the file \"datascience_extensions.py\" (on Canvas) and the file \"titanic3-table.csv\" (on Canvas) and then replace the next two cells (below) by a single code cell\n",
    "with the following two lines:\n",
    "\n",
    "from datascience_extensions import * <br>\n",
    "titanic = Table.read_table(\"titanic3-table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some new methods for class Table\n",
    "# Add IDS directory to search path\n",
    "\n",
    "course_dir = \"/Users/wxs/Dropbox/IDS/Git-reps/STAT180/\"\n",
    "computing_dir = course_dir + \"Computing\"\n",
    "\n",
    "if computing_dir not in sys.path:\n",
    "    sys.path.append(computing_dir)\n",
    "\n",
    "from datascience_extensions import *\n",
    "\n",
    "# Reload the extensions after we make a change\n",
    "# Importing it again does not work - a module is imported only once\n",
    "module_name = \"datascience_extensions\"\n",
    "importlib.reload(sys.modules[module_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed documentation for class Table is [here](http://data8.org/datascience/tables.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the titanic table\n",
    "data_dir = course_dir + \"Data/\"\n",
    "titanic_filename = \"titanic3-table.csv\"\n",
    "titanic_pathname = data_dir + titanic_filename\n",
    "titanic = Table.read_table(titanic_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.take(make_array(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Feature types </span>\n",
    "\n",
    "We distinguish between\n",
    "\n",
    "* unordered categorical features (\"sex\", \"embarked\")\n",
    "* ordered categorical features (\"pclass\")\n",
    "* numerical features (\"age\")\n",
    "\n",
    "For unordered categorical features, values can be either the same or different.\n",
    "There are no notions of order or distance.\n",
    "\n",
    "For ordered categorical features, category c1 can be larger, the same, or smaller than category c2.\n",
    "\n",
    "For numerical features there are notions of order and distance - it makes sense to compute and compare differences between values.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** The values of categorical features are often encoded as numbers, but that does not make them into numerical features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Summarizing and visualizing categorical features </span>\n",
    "\n",
    "We can summarize a categorical feature by the counts or the relative frequencies of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_count = titanic.group(\"pclass\")\n",
    "pclass_count\n",
    "\n",
    "# There were 323 passengers in 1st class...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pclass_count is a table\n",
    "\n",
    "pclass_count.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative frequencies are the counts divided by the total number of passengers. Let's make a table pclass_dist that has the relative frequencies instead of the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pclass_count.column(\"count\")\n",
    "rel_freq = count / sum(count)\n",
    "pclass_dist = pclass_count.drop(\"count\").with_column(\"rel_freq\", rel_freq)\n",
    "pclass_dist\n",
    "\n",
    "# It would be easy to write a function that takes a table of counts as input \n",
    "# and produces a table of relative frequencies. We will do this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of (category, relative frequency) pairs is called the **distribution** of a categorical feature.\n",
    "\n",
    "The most frequent category is called the **mode** of the distribution.\n",
    "\n",
    "Let's compute the mode of pclass_dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_mode = pclass_dist.sort(\"rel_freq\", descending = True).column(\"pclass\")[0]\n",
    "pclass_mode\n",
    "\n",
    "# Again, this calculation could be easily packaged into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_count.barh(\"pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_dist.barh(\"pclass\")\n",
    "\n",
    "# Looks the same. Only the scale is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_dist.barh(\"pclass\", \"rel_freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For unordered categorical variables we would like to sort the categories by count or relative frequency. This could be easily packaged into a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Summarizing numerical features </span>\n",
    "\n",
    "We want numerical summaries of\n",
    "\n",
    "* **location**: what is a \"typical\" value of the feature\n",
    "* **scale**: how large is the \"scatter\" of the values\n",
    "\n",
    "The most common measures of location are the \n",
    "* **mean** - the average of the values\n",
    "* **median** - the middle most value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = make_array(1, 25, 7)\n",
    "np.mean(foo)  # 33/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(foo)\n",
    "\n",
    "# One of the values is >= (smaller than or equal) 7, one is <= (less than or equal) 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = make_array(1, 25, 7, 9)\n",
    "np.median(foo)\n",
    "\n",
    "# If the number of observations is even, the median is the average of the two middle \n",
    "# most values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and median measure different characteristics of a feature.\n",
    "\n",
    "<img src=\"huff-mean-vs-median.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is **resistant** against outliers - it is a typical value for the bulk of the data. Outliers are common in real data (data entry errors, instrument failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_with_outlier = make_array(1, 25, 7, 9, 999)\n",
    "print(np.mean(foo_with_outlier))\n",
    "print(np.median(foo_with_outlier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "* Adding a constant c to all the values shifts the mean and the median by c\n",
    "* Multiplying all the values by a constant c multiplies the mean and the median by c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common measure of scale is the **standard deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_deviations_from_mean = (foo - np.mean(foo)) ** 2\n",
    "almost_mean_squared_deviation = sum(squared_deviations_from_mean) / (len(foo) - 1)\n",
    "\n",
    "# It is common to divide by (len(foo) - 1) rather than len(foo) for arcane \n",
    "# technical reasons\n",
    "\n",
    "sd = (almost_mean_squared_deviation) ** 0.5\n",
    "\n",
    "# We take the square root so that the measure of scale is in the same\n",
    "# units as the feature itself\n",
    "\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a function in numpy that computes the standard deviation\n",
    "\n",
    "np.std(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, np.std() divides by len(foo)\n",
    "# If we want to divide by len(foo) - 1 we have to suply an extra argument\n",
    "\n",
    "np.std(foo, ddof = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The square of the standard deviation is called the variance\n",
    "\n",
    "np.var(foo, ddof = 1) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A measure of scale that naturally goes with the median is the median absolute deviation from the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = np.median(abs(foo - np.median(foo)))\n",
    "mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like the median, the mad is resistant against outliers\n",
    "\n",
    "print(np.std(foo_with_outlier, ddof = 1))\n",
    "print(np.median(abs(foo_with_outlier - np.median(foo_with_outlier))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "* Adding a constant c to all the values leaves the standard deviation \n",
    "and the mad unchanged\n",
    "* Multiplying all the values by a constant c multiplies the standard deviation and the mad by abs(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Visualizing numerical features </span>\n",
    "\n",
    "Recall: The collection of (category, relative frequency) pairs is called the distribution of a categorical feature.\n",
    "\n",
    "We can draw the distribution of a numerical feature as a bar chart. Let's try that for the age of the titanic passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table with one column that has only the present (non-missing)\n",
    "# values of age and draw a bar chart\n",
    "\n",
    "age_count = titanic.select(\"age\").take_complete_rows().group(\"age\")\n",
    "\n",
    "# Convert to relative frequencies\n",
    "\n",
    "count = age_count.column(\"count\")\n",
    "rel_freq = count / sum(count)\n",
    "age_dist = age_count.drop(\"count\").with_column(\"rel_freq\", rel_freq)\n",
    "age_dist.bar(\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We get the general picture but the plot is pretty wiggly. \n",
    "\n",
    "For smaller data sets each value of the feature may occur only once, so the bars all would have the same hight. The only information would be in the spacing of the bars.\n",
    "\n",
    "We need to do some smoothing. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Histograms**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw one\n",
    "\n",
    "age = titanic.select(\"age\").take_complete_rows()\n",
    "bins = np.arange(0, 100, 10)\n",
    "age.hist(\"age\", bins = bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is the histogram computed?**\n",
    "\n",
    "* Choose bin boundaries, in our case 0, 10,...,90. The bins should cover the span of the data\n",
    "\n",
    "* Count for how many cases (rows) the value of the feature (\"age\") falls in each bin. The lower bin boundary is part of the bin, the upper bin boundary is not.\n",
    "\n",
    "* Draw a bar over each bin with area = relative freqency of cases for which the feature value falls in the bin.\n",
    "\n",
    "In our example the area of the leftmost bin is approximately 10 * 0.7 = 7, meaning ~7% of the passengers for whom we know the age were less than one year old.\n",
    "\n",
    "The most frequent age range is [20 years, 30 years) - the bin includes 20 years but does not include 30 years. About 33% of the passenger for whom we know the age were between between 20 and 29 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't provide the bins, the hist function will automatically \n",
    "# try to make a sensible choice.\n",
    "\n",
    "age.hist(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may be missing some features of the distribution. Let's try\n",
    "# a smaller bin width\n",
    "\n",
    "bins = np.arange(0, 90, 5)\n",
    "age.hist(\"age\", bins = bins)\n",
    "\n",
    "# Indeed there seems to ba age peak between 0 and ~4 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The age distribution also looks asymmetric.\n",
    "\n",
    "print(np.mean(age.column(\"age\")))\n",
    "print(np.median(age.column(\"age\")))\n",
    "\n",
    "# Suprising: I would have expected a bigger difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(age.column(\"age\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
